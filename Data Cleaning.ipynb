{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Machine Learning on Mortgage Loans\n",
    "### CAPP 30245 - Jacob Leppek, Rob Mitchell, Ryan Webb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Our analysis attempts to predict whether a completed mortgage loan application is approved or not using 2017 nationwide Consumer Financial Protection Bureau data accessed [here](https://www.consumerfinance.gov/data-research/hmda/). This data is accessible under the Home Mortgage Disclosure Act. We use 3 primary classification models to predict whether loans are approved: Decision Tree / Random Forest, Logistic Regression, and KNN. We break out these results to examine the importance of race in our models and its predictive power. We use multiple evaluation metrics to compare models: **INSERT METRICS HERE**. \n",
    "\n",
    "Overall, we find that **INSERT BEST MODEL HERE** is the most predictive model with an accuracy of **INSERT ACCURACY HERE** using features of **INSERT FEATURES HERE**.\n",
    "\n",
    "This analysis does not claim any interpretation as to the likelihood that an applicant can successfully pay back the loan, as the HMDA data does not include the relevant variables. The lack of a credit history, for instance, is a variable unreported by the HMDA but essential in the decision to originate (approve) a loan or not. \n",
    "\n",
    "These unreported variables do lead some academics to [question the validity](https://www.depauw.edu/learn/stata/Workshop/Munnell.pdf) of prior analyses that aim to demonstrate discrimination and borrowing credibility. To this, we can not directly estimate the casual effect of race or any other applicant characteristic has on the probability of a loan being approved. \n",
    "\n",
    "For this analysis, we seek only to determine whether, from the variables provided, whether we can predict if a loan is approved or denied. \n",
    "\n",
    "Code explanations for each feature may be accessed [here](https://files.consumerfinance.gov/hmda-historic-data-dictionaries/lar_record_codes.pdf).\n",
    "\n",
    "In this notebook, we clean and prepare the data to use for our machine learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hmda_2017_nationwide_all-records_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will drop the columns we won't be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['as_of_year',\n",
    "        'respondent_id',\n",
    "        'agency_code',\n",
    "        'owner_occupancy',\n",
    "        'preapproval',\n",
    "        'applicant_race_2',\n",
    "        'applicant_race_3',\n",
    "        'applicant_race_4',\n",
    "        'applicant_race_5',\n",
    "        'co_applicant_race_2',\n",
    "        'co_applicant_race_3',\n",
    "        'co_applicant_race_4',\n",
    "        'co_applicant_race_5',\n",
    "        'purchaser_type',\n",
    "        'denial_reason_1',\n",
    "        'denial_reason_2',\n",
    "        'denial_reason_3',\n",
    "        'hoepa_status',\n",
    "        'lien_status',\n",
    "        'edit_status',\n",
    "        'sequence_number',\n",
    "        'application_date_indicator',\n",
    "        'msamd',\n",
    "        'state_code',\n",
    "        'county_code',\n",
    "        'census_tract_number',\n",
    "        'rate_spread']\n",
    "\n",
    "df = df.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will drop rows with values that we aren't including in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude rows where action taken is withdrawn or incomplete\n",
    "df = df[~df['action_taken'].isin([4, 5])]\n",
    "# Exclude rows where loan type is not conventional\n",
    "df = df[df['loan_type'] == 1]\n",
    "# Exclude rows where the purpose of the loan is not to purchase a house\n",
    "df = df[df['loan_purpose'] == 1]\n",
    "# Exclude rows where property type is not 1-4 family\n",
    "df = df[df['property_type'] == 1]\n",
    "# Exclude rows where information on applicant race is not provided or not applicable\n",
    "df = df[~df['applicant_race_1'].isin([6, 7])]\n",
    "# Exclude rows where information on applicant ethnicity is not provided or not applicable\n",
    "df = df[~df['applicant_ethnicity'].isin([3, 4])]\n",
    "# Exclude rows where information on applicant sex is not provided or not applicable\n",
    "df = df[df['applicant_sex'].isin([1, 2])]\n",
    "# Drop columns that now only have 1 values\n",
    "cols = ['loan_type',\n",
    "        'property_type',\n",
    "        'loan_purpose'\n",
    "       ]\n",
    "df = df.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['action_taken'].apply(lambda x: 1 if x in [1, 6] else 0)\n",
    "df = df.drop(columns=['action_taken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create some features based on variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change applicant sex from 1 and 2 to 1 and 0 (1 is male)\n",
    "df['applicant_sex'] = df['applicant_sex'].apply(lambda x: 1 if x == 1 else 0)\n",
    "# This feature indicates how much money the loan is for relative to the applicant's income\n",
    "df['loan_income_ratio'] = df['loan_amount_000s'] / df['applicant_income_000s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the existence of co-applicant ethnicity, race, or sex to create a binary indicator of whether a [co-applicant](https://www.investopedia.com/terms/c/co-applicant.asp) exists. From prior research, it appears that having a co-applicant can have [statistically significant effects](https://journals.sagepub.com/doi/abs/10.1177/08861090022093804) on whether the loan is approved or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['co_applicant'] = np.where((df['co_applicant_ethnicity'] != 5) | \n",
    "                              (df['co_applicant_race_1'] != 8) |\n",
    "                              (df['co_applicant_sex'] != 5), 1, 0)\n",
    "df = df.drop(columns=['co_applicant_ethnicity', 'co_applicant_race_1', 'co_applicant_sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The applicant is a minority if their race or ethnicity indicates so\n",
    "df['applicant_minority'] = df.apply(lambda row: 1 if row['applicant_race_1'] in [1, 2, 3, 4] or\n",
    "                                                     row['applicant_ethnicity'] == 1\n",
    "                                                  else 0,\n",
    "                                    axis=1)\n",
    "# We will preserve the race an ethnicity columns for future analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly 55,000 records have NaNs for all accompanying U.S. Census data (population, minority population, etc). On examination, we found that none of these loan applications were approved. This comes to 7.9% of the records. We have two options at this point:\n",
    "\n",
    "1. Impute values to the extent possible after splitting the data into training and test sets. We have state codes for roughly 17,000 of these records. We could use the median value of each state FIPS code to impute the values, and impute the rest as the median of all other values. However, since no variation exists in our target variable for these records, imputting the data would likely heavily affect our estimator.\n",
    "\n",
    "2. Drop these records. Dropping any rows with NaNs in the Census data reveals exact overlap across the missing values. Dropping these records make sense; given that no variance in the outcome exists for these records, it is likely that imputing these values will cause overfitting in our estimator. With this said, it seems unlikely that these values are missing entirely at random, and dropping these records may introduce bias into our estimators.\n",
    "\n",
    "We chose to drop these records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export this clean data to a csv for use in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
